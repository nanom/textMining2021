\section{Conclusions and Future directions}
% El esfuerzo principal de este trabajo fue destinado a obtener una desagregación de las clases mayoritarias del conjunto de preguntas a respuestas visuales VizWiz-VQA. 
% En una primera etapa, se emplearon técnicas no supervisadas y distintas estrategias de codificación de datos de entrada, con el fin de  alimentar al algorítmo de clusterización con el embedding que mejores resultados entregara. En esta parte, se utilizo el algoritmo KMeans como método de clusterización, y dos estrategias de embedding: una basada en construcción de matrices de ocurrencia mediante n-gramas + reducción de dimensionalid, y la otra, mediante modelos pre-entrenados de embedding neuronales, tales como fastText y doc2Vec.
The main effort of this work was aimed at obtaining a disaggregation of the majority classes of the set of visual questions VizWiz-VQA.
In a first stage, unsupervised techniques and different input data coding strategies were used, in order to feed the clustering algorithm with the embedding that would deliver the best results. In this part, the \emph{KMeans} algorithm was used as a clustering method, and two embedding strategies: one based on the construction of occurrence matrices through n-grams + dimensionalid reduction, and the other, through pre-trained neural embedding models. such as \emph{fastText} and \emph{doc2Vec}.

% Posterior a la clusterización, se inició un proceso de análisis de resultados en busca de propiedades y catracterísticas que permitieran identificar naturalmente cada uno de los clusteres obtenidos. Como consecuencia, se propuso un conjunto de 8 nuevas categorias: \textbf{choice, color, explanation, ident, observation, ocr, rel\_ident, yes\_no}, sentando las bases para el desarrollo de la segunda fase del proyecto. El objetivo de la identificación de nuevas clases para sustituir las ya predefinidas en el conjunto de datos originales, se debió a que estas últimas, son inespecificas y no permiten conocer en profundidad el tipo y naturaleza de preguntas que contienen.
After the clustering, a process of analysis of the results was started in search of properties and characteristics that would allow the natural identification of each one of the clusters obtained. As a consequence, a set of 8 new categories was proposed: \emph{choice, color, explanation, ident, observation, ocr, rel\_ident, yes\_no}, laying the foundations for the development of the second phase of the project. The objective of identifying new classes to replace those already predefined in the original dataset was due to the fact that the latter are unspecific and do not allow in-depth knowledge of the type and nature of questions they contain.

% Con las nuevas clases ya definidas, en la segunda estapa, se entrenaron dos modelos de clasificadores: Logistic Regression y Linear Suport Vector CLassification. Además, con la finalidad de que el modelo final fuera capaz de etiquetar a cualquier pregunta por fuera de los grupos de entrenamiento y testeo utilizados, los datos de entrada para tal entrenamiento (en este caso, las preguntas), fueron codificados probando dos modelos pre-entrenados de embedding neuronales, ámbos en el estado del arte: bert\_base\_uncased y all-MiniLM-L6-v2. Como resultado, luego de poner a prueba cuatro combinaciones (modelo de embedding, modelo de clasificación), se seleccionó a la tupla (bert\_base\_uncased, LinearSVC) como modelo definitifo, entregando $\sim$98\% de precisión en el conjunto de preguntas de testeo.
With the new classes already defined, in the second stage, two classifier models were trained: \emph{Logistic Regression} and \emph{Linear Suport Vector Classification}. In addition, in order for the final model to be able to label any question outside of the training and testing groups used, the input data for such training (in this case, the questions) were coded by testing two pre-trained models of neural embedding, both in the state of the art: \emph{bert\_base\_uncased} and \emph{all-MiniLM-L6-v2}. As a result, after testing four combinations (embedding model, classification model), the tuple \emph{bert\_base\_uncased + LinearSVC} was selected as the definitive model, giving $\sim$ 98\% precision in the set of test questions.

% Posteriormente, con el modelo de clasificación entrenado sobre las nuevas categorías de preguntas propuestas, se pudo realizar el esperado desagregado del conjunto completo de VizWiz-VQA. Los resultados obtenidos al etiquetar todas las preguntas con las nuevas 8 clases, permitieron conocer varios puntos importantes. 
Subsequently, with the classification model trained on the new proposed question categories, the expected disaggregation of the complete set of VizWiz-VQA could be carried out. The results obtained when labeling all the questions with the new 8 classes, allowed to know several important points.

% Las antiguas clases `yes/no' y `number', fueron las dos categorizaciones mas puras encontradas. Para la primera, casi el 83\% de las respuestas eran binarias. Por otro lasdo, en la clase `number' se observó que no solo habia preguntas relacionadas directamente al reconocimiento de números en algun entorno dado, sino que  también, preguntas relacionadas a conteos de objetos formaban el $\sim$39\% del grupo y no requerían de capacidades OCR.
% Con respecto a las clases más emblemáticas, en `other' las preguntas caian principalmente dentro de tres subcategorías, siendo las relacionadas con la identificación de objetos la destacada, seguida por preguntas de tipo relacionales y por último de identificación de colores.Para el caso de `unanswereable', se identificaron cuatro tipos de predicciones principales: `explication', `ident', `rel\_ident', `yes\_no'. De estas, las tres primeras son categorías de preguntas muy dificiles de responder ya que requieren capacidades de razonamiento, conocimientos previos y manejo de la perspectiva muy grandes; si a esto se le suma las caracterizticas malas calidades de las imágenes asociadas, no sería una sorpresa que este tipo de preguntas ocupen esta misteriosa clasificación.
The old classes `yes/no' and `number', were the two purest categorizations found. For the first one, almost 83\% of the answers were binary. On the other hand, in the class `number' it was observed that not only were there questions directly related to the recognition of numbers in some given environment, but also, questions related to object counts made up $\sim$ 39\% of the group and not required OCR capabilities.
With respect to the most emblematic classes, in `other' the questions fell mainly into three subcategories, those related to the identification of objects being the most prominent, followed by relational questions and finally color identification. For the case of `unanswerable', four main types of predictions were identified: `explication', `ident', `rel\_ident' and `yes\_no'. Of these, the first three are categories of questions that are very difficult to answer since they require very great reasoning skills, prior knowledge and management of perspective; if to this is added the characteristic poor qualities of the associated images, it would not be a surprise that these types of questions occupy this mysterious classification.


% Para finalizar, y pensando en posibles trabajos futuros, se planean utilizar los resultados del modelo de clasificación para entrenar un modelo de preguntas y respuestas condicionado (cQ\&A). Es decir, con las preguntas re-clasificadas, se alimentara el nuevo modelo, no solo con la pregunta de interes, sino con un condicionamiento extra, su categoría. De esta forma, y al igual que lo hacen los algoritmos cGAN (Conditional Generative Adversarial Networks), se podra diriguir el resultado. Esto, es muy interesante ya que preguntas del estilo \emph{`Could you tell me what color is this?'}, que trivialmente serían respondidas con si/no, al pasarle por ejemplo la categoría  `color', se forzaría al modelo para que con suerte, devolviera como respuesta el nombre de un color,  desambiguando la pregunta para recibir el típo específico de respuesta que se desee.
Finally, and thinking about possible future work, it is planned to use the results of the classification model to train a conditioned question and answer model (cQ\&A). That is, with the re-classified questions, the new model will be fed, not only with the question of interest, but also with an extra conditioning, its category. In this way, and as the cGANs \cite{cGans} (Conditional Generative Adversarial Networks) algorithms do, the result can be directed. This is very interesting since questions of the style \emph{`Could you tell me what color is this?'}, which would trivially be answered with yes|no, when passing for example the category `color', the model would be forced to hopefully it will return the name of a color, disambiguating the question to receive the specific type of response that is desired.